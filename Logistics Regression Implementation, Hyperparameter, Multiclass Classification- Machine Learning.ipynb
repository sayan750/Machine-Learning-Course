{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8e47e2",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Logistic regression is a popular machine learning algorithm used for binary classification tasks, where the goal is to predict one of two possible outcomes. Despite its name, logistic regression is a classification algorithm rather than a regression algorithm. The underlying principle of logistic regression is based on the logistic function (also known as the sigmoid function), which maps any real-valued number to a value between 0 and 1. This makes it suitable for modeling the probability of a binary outcome.\n",
    "\n",
    "Here's a step-by-step overview of how logistic regression works:\n",
    "\n",
    "1. Data Preparation: Start by collecting a labeled dataset, where each data point is associated with a binary outcome (0 or 1) and a set of input features. Ensure the data is preprocessed and any necessary feature engineering steps are performed.\n",
    "\n",
    "2. Model Training: Initialize the logistic regression model with random weights. The goal is to learn the optimal weights that minimize the error between predicted probabilities and actual labels. This is typically done using an optimization algorithm like gradient descent or its variants.\n",
    "\n",
    "3. Feature Scaling: Optionally, perform feature scaling to normalize the input features. This step can improve the convergence of the optimization algorithm and make training more efficient.\n",
    "\n",
    "4. Hypothesis Function: The logistic regression model applies a linear combination of the input features and weights, followed by the logistic function to obtain the predicted probability. The hypothesis function is defined as: h(x) = sigmoid(w₀ + w₁x₁ + w₂x₂ + ... + wₙxₙ). Here, h(x) is the predicted probability, w₀, w₁, ..., wₙ are the weights, and x₁, x₂, ..., xₙ are the input features.\n",
    "\n",
    "5. Loss Function: The next step is to define a loss function that quantifies the difference between the predicted probabilities and the actual labels. In logistic regression, the most commonly used loss function is the binary cross-entropy loss, given by: L(y, h(x)) = -[y * log(h(x)) + (1 - y) * log(1 - h(x))]. Here, y represents the true label (0 or 1) and h(x) is the predicted probability.\n",
    "\n",
    "6. Gradient Descent: To minimize the loss function, gradient descent is commonly employed. The weights are iteratively updated by taking steps in the direction of steepest descent of the loss function's gradient. This process continues until convergence is achieved or a predefined number of iterations is reached.\n",
    "\n",
    "7. Prediction: Once the model is trained, it can be used to make predictions on new, unseen data. A common threshold of 0.5 is used to convert the predicted probabilities into binary predictions. If the predicted probability is greater than or equal to 0.5, the output is assigned the positive class label; otherwise, it is assigned the negative class label.\n",
    "\n",
    "Logistic regression is a linear model and assumes a linear relationship between the input features and the log-odds of the binary outcome. It can be extended to handle multiclass classification problems using techniques like one-vs-rest or multinomial logistic regression.\n",
    "\n",
    "Note that logistic regression has some assumptions and limitations, such as the linearity assumption and sensitivity to outliers. It's important to evaluate the performance of the model using appropriate metrics and consider other algorithms if the assumptions are violated or the performance is unsatisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0009a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5701140",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82596aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5143c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ef4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8fa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb90630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5476e2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0c2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf5f9cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "916c44ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b26022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                 5.1               3.5                1.4               0.2   \n",
       "1                 4.9               3.0                1.4               0.2   \n",
       "2                 4.7               3.2                1.3               0.2   \n",
       "3                 4.6               3.1                1.5               0.2   \n",
       "4                 5.0               3.6                1.4               0.2   \n",
       "..                ...               ...                ...               ...   \n",
       "95                5.7               3.0                4.2               1.2   \n",
       "96                5.7               2.9                4.2               1.3   \n",
       "97                6.2               2.9                4.3               1.3   \n",
       "98                5.1               2.5                3.0               1.1   \n",
       "99                5.7               2.8                4.1               1.3   \n",
       "\n",
       "    target  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "95       1  \n",
       "96       1  \n",
       "97       1  \n",
       "98       1  \n",
       "99       1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['target']!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba370542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df[df['target']!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f48e294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f39e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Independent and dependent features\n",
    "X=df_copy.iloc[:,:-1]\n",
    "y=df_copy.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e95c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "851caaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7d50049",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = LogisticRegression(max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9049851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a95109a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51c6738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= classification.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acaa6009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093832b6",
   "metadata": {},
   "source": [
    "## Confusion Metrics,Accuracy,Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce0faa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eac25b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0]\n",
      " [ 0  8]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cef57cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e52486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c947e43",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c7f5e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67952206",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=KFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6d75b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08ca75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9f387e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## these are the scores all the cross validation\n",
    "scores = cross_val_score(classification,X_train,y_train,scoring='accuracy',cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df47bd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Final Scores\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892dec0d",
   "metadata": {},
   "source": [
    "## Another Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e907932",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets see more complex data\n",
    "## make a prediction with a multinomial logistic regression model\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09753a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e374e963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.56999479, -0.13019997,  3.16075093, ..., -1.93094078,\n",
       "         3.26130366,  2.05692145],\n",
       "       [ 0.34129317,  2.51321418, -0.80416572, ...,  6.24734437,\n",
       "        -1.92769365,  2.9503149 ],\n",
       "       [ 2.27539972,  3.36561455,  0.17164362, ...,  2.74693781,\n",
       "         0.13492444,  2.00339547],\n",
       "       ...,\n",
       "       [ 0.5234359 ,  1.90466429,  0.93243365, ...,  1.53945231,\n",
       "         1.90646166,  1.99458587],\n",
       "       [ 1.33747921,  3.25859684,  0.78792366, ...,  5.18788314,\n",
       "        -0.82071083,  3.51411431],\n",
       "       [-0.98534299,  0.83919047,  2.5820803 , ...,  3.04705685,\n",
       "         0.66885641,  3.32838496]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e0d9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1acf3350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8999ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_class_model=LogisticRegression(max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e578061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_class_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc6d699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_complex = complex_class_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e702eb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78 13]\n",
      " [29 80]]\n",
      "0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79        91\n",
      "           1       0.86      0.73      0.79       109\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.80      0.79       200\n",
      "weighted avg       0.80      0.79      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_complex))\n",
    "print(accuracy_score(y_test,y_pred_complex))\n",
    "print(classification_report(y_test,y_pred_complex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94732a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80625, 0.78125, 0.79375, 0.8125 , 0.85625])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=KFold(n_splits=5)\n",
    "cross_val_score(complex_class_model,X_train,y_train,cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc5aa14",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning is an important step in training machine learning models, including logistic regression. Tuning the hyperparameters allows you to find the optimal settings that result in the best model performance. Here are some common hyperparameters for logistic regression and strategies for tuning them:\n",
    "\n",
    "1. Regularization parameter (C or alpha): This parameter controls the inverse of the regularization strength. A smaller value of C or a larger value of alpha increases the regularization strength, which can prevent overfitting. To tune this parameter, you can try different values on a logarithmic scale, such as [0.001, 0.01, 0.1, 1, 10, 100]. Use techniques like cross-validation to evaluate the performance of each setting and select the one that gives the best results.\n",
    "\n",
    "2. Penalty type (L1 or L2): Logistic regression can use either L1 or L2 regularization. L1 regularization can lead to sparse solutions by driving some coefficients to exactly zero, while L2 regularization encourages small non-zero coefficients. You can try both penalty types and see which one works better for your problem. Some libraries provide a combined penalty option (e.g., Elastic Net), which allows you to mix both L1 and L2 penalties.\n",
    "\n",
    "3. Solver algorithm: Logistic regression models can be optimized using different algorithms, such as 'liblinear', 'lbfgs', 'sag', or 'saga'. The choice of the solver depends on the size of your dataset, the regularization type, and the specific problem you are working on. Experiment with different solvers to find the one that gives the best results.\n",
    "\n",
    "4. Maximum number of iterations: This parameter determines the maximum number of iterations taken for the solver to converge. If the solver fails to converge, you can increase this value. However, keep in mind that a large number of iterations can increase the training time. Start with a reasonable default value and increase it only if necessary.\n",
    "\n",
    "5. Class weights: In imbalanced datasets, where one class is much more prevalent than the other, assigning different weights to the classes can help improve model performance. Some libraries provide options to specify class weights during model training. Try assigning higher weights to the minority class and lower weights to the majority class to account for the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81819478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09740375",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5074df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9da92",
   "metadata": {},
   "source": [
    "## Model Training Hyperparameter Tuning\n",
    "\n",
    "## GridsearchCV\n",
    "\n",
    "GridSearchCV is a function provided by the scikit-learn library in Python, which is used for hyperparameter tuning and model selection. It automates the process of searching for the best combination of hyperparameters by exhaustively evaluating all possible parameter combinations using cross-validation.\n",
    "\n",
    "Here's a general outline of how GridSearchCV works:\n",
    "\n",
    "1. You start by defining a parameter grid, which is a dictionary or a list of dictionaries. Each dictionary contains the hyperparameters you want to tune and the corresponding values to try.\n",
    "\n",
    "2. Instantiate an estimator object for the machine learning algorithm you want to use, such as a classifier or a regression model.\n",
    "\n",
    "3. Create a GridSearchCV object, providing the estimator, parameter grid, and the number of folds for cross-validation.\n",
    "\n",
    "4. Fit the GridSearchCV object to your training data. This will iterate through all the parameter combinations, fitting the estimator and evaluating its performance using cross-validation.\n",
    "\n",
    "5. Once the fitting process is complete, you can access various attributes of the GridSearchCV object to examine the results. For example, you can obtain the best set of hyperparameters found, the best cross-validated score, or detailed information about each parameter combination's performance.\n",
    "\n",
    "6. Finally, you can use the best estimator found by GridSearchCV to make predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4bdea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4aacd36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty':('l1', 'l2', 'elasticnet'), 'C':[1,10,20,30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dbfeb3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa5cb573",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(classifier,param_grid=parameters,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6c9c480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 10, 20, 30],\n",
       "                         'penalty': ('l1', 'l2', 'elasticnet')})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Splitting of Training data to train and validation\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c55dc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1be8495d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8087500000000001"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da778b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(C=1,penalty=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c6925cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d85a1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88405df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a92c972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71649202, 0.28350798],\n",
       "       [0.19508969, 0.80491031],\n",
       "       [0.12418141, 0.87581859],\n",
       "       [0.05045906, 0.94954094],\n",
       "       [0.88775659, 0.11224341],\n",
       "       [0.75067497, 0.24932503],\n",
       "       [0.97980488, 0.02019512],\n",
       "       [0.3921745 , 0.6078255 ],\n",
       "       [0.59920135, 0.40079865],\n",
       "       [0.39295203, 0.60704797],\n",
       "       [0.20428696, 0.79571304],\n",
       "       [0.80257879, 0.19742121],\n",
       "       [0.86422932, 0.13577068],\n",
       "       [0.92665682, 0.07334318],\n",
       "       [0.00131743, 0.99868257],\n",
       "       [0.04171096, 0.95828904],\n",
       "       [0.56288536, 0.43711464],\n",
       "       [0.89322764, 0.10677236],\n",
       "       [0.29278211, 0.70721789],\n",
       "       [0.00870994, 0.99129006],\n",
       "       [0.71879454, 0.28120546],\n",
       "       [0.5108267 , 0.4891733 ],\n",
       "       [0.76230298, 0.23769702],\n",
       "       [0.73170811, 0.26829189],\n",
       "       [0.10155737, 0.89844263],\n",
       "       [0.04046512, 0.95953488],\n",
       "       [0.57926768, 0.42073232],\n",
       "       [0.00526468, 0.99473532],\n",
       "       [0.03101648, 0.96898352],\n",
       "       [0.96093035, 0.03906965],\n",
       "       [0.85436626, 0.14563374],\n",
       "       [0.79066609, 0.20933391],\n",
       "       [0.39037776, 0.60962224],\n",
       "       [0.41338022, 0.58661978],\n",
       "       [0.98206185, 0.01793815],\n",
       "       [0.04761009, 0.95238991],\n",
       "       [0.56730931, 0.43269069],\n",
       "       [0.77935536, 0.22064464],\n",
       "       [0.07934242, 0.92065758],\n",
       "       [0.89312261, 0.10687739],\n",
       "       [0.91175979, 0.08824021],\n",
       "       [0.03570627, 0.96429373],\n",
       "       [0.77423589, 0.22576411],\n",
       "       [0.82809097, 0.17190903],\n",
       "       [0.27335009, 0.72664991],\n",
       "       [0.41095636, 0.58904364],\n",
       "       [0.41677883, 0.58322117],\n",
       "       [0.30255724, 0.69744276],\n",
       "       [0.23219193, 0.76780807],\n",
       "       [0.42904108, 0.57095892],\n",
       "       [0.72270466, 0.27729534],\n",
       "       [0.6217827 , 0.3782173 ],\n",
       "       [0.20371163, 0.79628837],\n",
       "       [0.05210741, 0.94789259],\n",
       "       [0.77677403, 0.22322597],\n",
       "       [0.11773028, 0.88226972],\n",
       "       [0.83785616, 0.16214384],\n",
       "       [0.05970904, 0.94029096],\n",
       "       [0.03070294, 0.96929706],\n",
       "       [0.0218836 , 0.9781164 ],\n",
       "       [0.56750492, 0.43249508],\n",
       "       [0.35924456, 0.64075544],\n",
       "       [0.55122582, 0.44877418],\n",
       "       [0.15643693, 0.84356307],\n",
       "       [0.76262024, 0.23737976],\n",
       "       [0.63267612, 0.36732388],\n",
       "       [0.59654318, 0.40345682],\n",
       "       [0.00261832, 0.99738168],\n",
       "       [0.83421167, 0.16578833],\n",
       "       [0.59786443, 0.40213557],\n",
       "       [0.14037801, 0.85962199],\n",
       "       [0.84084988, 0.15915012],\n",
       "       [0.9678567 , 0.0321433 ],\n",
       "       [0.84650481, 0.15349519],\n",
       "       [0.03509667, 0.96490333],\n",
       "       [0.96245324, 0.03754676],\n",
       "       [0.74723939, 0.25276061],\n",
       "       [0.70026117, 0.29973883],\n",
       "       [0.47986928, 0.52013072],\n",
       "       [0.00367136, 0.99632864],\n",
       "       [0.78634741, 0.21365259],\n",
       "       [0.06364814, 0.93635186],\n",
       "       [0.58068352, 0.41931648],\n",
       "       [0.05007273, 0.94992727],\n",
       "       [0.90506055, 0.09493945],\n",
       "       [0.06616827, 0.93383173],\n",
       "       [0.66831758, 0.33168242],\n",
       "       [0.92734742, 0.07265258],\n",
       "       [0.55721961, 0.44278039],\n",
       "       [0.74709365, 0.25290635],\n",
       "       [0.77522455, 0.22477545],\n",
       "       [0.63486972, 0.36513028],\n",
       "       [0.01438777, 0.98561223],\n",
       "       [0.52834723, 0.47165277],\n",
       "       [0.02023639, 0.97976361],\n",
       "       [0.83864488, 0.16135512],\n",
       "       [0.01944111, 0.98055889],\n",
       "       [0.61155652, 0.38844348],\n",
       "       [0.92720153, 0.07279847],\n",
       "       [0.11587958, 0.88412042],\n",
       "       [0.00354271, 0.99645729],\n",
       "       [0.58325903, 0.41674097],\n",
       "       [0.28113047, 0.71886953],\n",
       "       [0.69464975, 0.30535025],\n",
       "       [0.06257916, 0.93742084],\n",
       "       [0.97562318, 0.02437682],\n",
       "       [0.11304658, 0.88695342],\n",
       "       [0.75903518, 0.24096482],\n",
       "       [0.0031531 , 0.9968469 ],\n",
       "       [0.55689244, 0.44310756],\n",
       "       [0.5739699 , 0.4260301 ],\n",
       "       [0.91482094, 0.08517906],\n",
       "       [0.51736949, 0.48263051],\n",
       "       [0.91039931, 0.08960069],\n",
       "       [0.52669851, 0.47330149],\n",
       "       [0.00317796, 0.99682204],\n",
       "       [0.04103979, 0.95896021],\n",
       "       [0.1322328 , 0.8677672 ],\n",
       "       [0.14655423, 0.85344577],\n",
       "       [0.33721267, 0.66278733],\n",
       "       [0.04056386, 0.95943614],\n",
       "       [0.09980328, 0.90019672],\n",
       "       [0.85588908, 0.14411092],\n",
       "       [0.11112541, 0.88887459],\n",
       "       [0.55233312, 0.44766688],\n",
       "       [0.88883871, 0.11116129],\n",
       "       [0.89061098, 0.10938902],\n",
       "       [0.1304353 , 0.8695647 ],\n",
       "       [0.90733258, 0.09266742],\n",
       "       [0.74998725, 0.25001275],\n",
       "       [0.75792848, 0.24207152],\n",
       "       [0.76793966, 0.23206034],\n",
       "       [0.47106832, 0.52893168],\n",
       "       [0.95073863, 0.04926137],\n",
       "       [0.983106  , 0.016894  ],\n",
       "       [0.92995953, 0.07004047],\n",
       "       [0.03517907, 0.96482093],\n",
       "       [0.49980354, 0.50019646],\n",
       "       [0.36629905, 0.63370095],\n",
       "       [0.848895  , 0.151105  ],\n",
       "       [0.8653365 , 0.1346635 ],\n",
       "       [0.52580322, 0.47419678],\n",
       "       [0.95457175, 0.04542825],\n",
       "       [0.41555788, 0.58444212],\n",
       "       [0.96203548, 0.03796452],\n",
       "       [0.99135738, 0.00864262],\n",
       "       [0.70670396, 0.29329604],\n",
       "       [0.06633492, 0.93366508],\n",
       "       [0.0508162 , 0.9491838 ],\n",
       "       [0.01960543, 0.98039457],\n",
       "       [0.84240385, 0.15759615],\n",
       "       [0.95530269, 0.04469731],\n",
       "       [0.788731  , 0.211269  ],\n",
       "       [0.97487695, 0.02512305],\n",
       "       [0.77665172, 0.22334828],\n",
       "       [0.93042505, 0.06957495],\n",
       "       [0.04241954, 0.95758046],\n",
       "       [0.23806093, 0.76193907],\n",
       "       [0.69716204, 0.30283796],\n",
       "       [0.0576568 , 0.9423432 ],\n",
       "       [0.0506892 , 0.9493108 ],\n",
       "       [0.89205545, 0.10794455],\n",
       "       [0.83103359, 0.16896641],\n",
       "       [0.38537408, 0.61462592],\n",
       "       [0.01845132, 0.98154868],\n",
       "       [0.82385323, 0.17614677],\n",
       "       [0.78506499, 0.21493501],\n",
       "       [0.03071641, 0.96928359],\n",
       "       [0.08149283, 0.91850717],\n",
       "       [0.77568633, 0.22431367],\n",
       "       [0.93130069, 0.06869931],\n",
       "       [0.01229257, 0.98770743],\n",
       "       [0.11056039, 0.88943961],\n",
       "       [0.80004548, 0.19995452],\n",
       "       [0.01102466, 0.98897534],\n",
       "       [0.04413068, 0.95586932],\n",
       "       [0.98195125, 0.01804875],\n",
       "       [0.03145616, 0.96854384],\n",
       "       [0.26099824, 0.73900176],\n",
       "       [0.8191255 , 0.1808745 ],\n",
       "       [0.39971207, 0.60028793],\n",
       "       [0.37467582, 0.62532418],\n",
       "       [0.7784229 , 0.2215771 ],\n",
       "       [0.74064048, 0.25935952],\n",
       "       [0.46013926, 0.53986074],\n",
       "       [0.53947825, 0.46052175],\n",
       "       [0.03656668, 0.96343332],\n",
       "       [0.00858922, 0.99141078],\n",
       "       [0.91595892, 0.08404108],\n",
       "       [0.11711168, 0.88288832],\n",
       "       [0.61465028, 0.38534972],\n",
       "       [0.0339813 , 0.9660187 ],\n",
       "       [0.01539839, 0.98460161],\n",
       "       [0.06560115, 0.93439885],\n",
       "       [0.90049527, 0.09950473],\n",
       "       [0.04924743, 0.95075257],\n",
       "       [0.87255588, 0.12744412],\n",
       "       [0.02147135, 0.97852865],\n",
       "       [0.64457615, 0.35542385],\n",
       "       [0.00987407, 0.99012593]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00e1d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2dd60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78 13]\n",
      " [29 80]]\n",
      "0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79        91\n",
      "           1       0.86      0.73      0.79       109\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.80      0.79       200\n",
      "weighted avg       0.80      0.79      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1336f2",
   "metadata": {},
   "source": [
    "## Randomized Search cv\n",
    "\n",
    "RandomizedSearchCV (Randomized Search Cross-Validation) is a technique for hyperparameter tuning in machine learning models. It is an alternative to GridSearchCV that allows you to sample a subset of possible hyperparameter values from a defined search space. The RandomizedSearchCV technique is useful when the hyperparameter search space is large, and it is impractical to perform an exhaustive search using GridSearchCV. Instead of trying out all possible combinations, RandomizedSearchCV selects a random subset of hyperparameter values and evaluates the model's performance using cross-validation.\n",
    "\n",
    "Here is a step-by-step overview of how RandomizedSearchCV works:\n",
    "\n",
    "1. Define the search space: Specify the hyperparameters you want to tune and the corresponding value ranges or distributions. For example, you might define a search space for a decision tree classifier with parameters like the maximum depth, minimum samples split, and maximum features.\n",
    "\n",
    "2. Set the number of iterations: Determine the number of iterations or samples you want to draw from the search space during the search. This parameter is typically set based on computational resources and time constraints.\n",
    "\n",
    "3. Define the scoring metric: Specify the evaluation metric that will be used to assess the performance of the model with different hyperparameter settings. Common metrics include accuracy, precision, recall, F1 score, or custom scoring functions.\n",
    "\n",
    "4. Perform RandomizedSearchCV: RandomizedSearchCV performs a specified number of iterations by randomly sampling hyperparameters from the defined search space. For each combination of hyperparameters, it trains and evaluates the model using cross-validation.\n",
    "\n",
    "5. Select the best hyperparameters: After all iterations are completed, RandomizedSearchCV returns the best set of hyperparameters based on the scoring metric you specified.\n",
    "\n",
    "6. Evaluate the model: Once you have obtained the best hyperparameters, you can retrain the model using the entire training dataset with those hyperparameters and evaluate its performance on a separate test set or using other evaluation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de23336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbb9347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf=RandomizedSearchCV(LogisticRegression(),param_distributions=parameters,cv=5,n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12b73314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=20,\n",
       "                   param_distributions={'C': [1, 10, 20, 30],\n",
       "                                        'penalty': ('l1', 'l2', 'elasticnet')})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ea5bef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=20,\n",
       "                   param_distributions={'C': [1, 10, 20, 30],\n",
       "                                        'penalty': ('l1', 'l2', 'elasticnet')})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1ba3b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2', 'C': 1}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a27bcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8087500000000001"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38dc9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(C=1,penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dfbd618b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c02d0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6f22fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9608eafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71649202, 0.28350798],\n",
       "       [0.19508969, 0.80491031],\n",
       "       [0.12418141, 0.87581859],\n",
       "       [0.05045906, 0.94954094],\n",
       "       [0.88775659, 0.11224341],\n",
       "       [0.75067497, 0.24932503],\n",
       "       [0.97980488, 0.02019512],\n",
       "       [0.3921745 , 0.6078255 ],\n",
       "       [0.59920135, 0.40079865],\n",
       "       [0.39295203, 0.60704797],\n",
       "       [0.20428696, 0.79571304],\n",
       "       [0.80257879, 0.19742121],\n",
       "       [0.86422932, 0.13577068],\n",
       "       [0.92665682, 0.07334318],\n",
       "       [0.00131743, 0.99868257],\n",
       "       [0.04171096, 0.95828904],\n",
       "       [0.56288536, 0.43711464],\n",
       "       [0.89322764, 0.10677236],\n",
       "       [0.29278211, 0.70721789],\n",
       "       [0.00870994, 0.99129006],\n",
       "       [0.71879454, 0.28120546],\n",
       "       [0.5108267 , 0.4891733 ],\n",
       "       [0.76230298, 0.23769702],\n",
       "       [0.73170811, 0.26829189],\n",
       "       [0.10155737, 0.89844263],\n",
       "       [0.04046512, 0.95953488],\n",
       "       [0.57926768, 0.42073232],\n",
       "       [0.00526468, 0.99473532],\n",
       "       [0.03101648, 0.96898352],\n",
       "       [0.96093035, 0.03906965],\n",
       "       [0.85436626, 0.14563374],\n",
       "       [0.79066609, 0.20933391],\n",
       "       [0.39037776, 0.60962224],\n",
       "       [0.41338022, 0.58661978],\n",
       "       [0.98206185, 0.01793815],\n",
       "       [0.04761009, 0.95238991],\n",
       "       [0.56730931, 0.43269069],\n",
       "       [0.77935536, 0.22064464],\n",
       "       [0.07934242, 0.92065758],\n",
       "       [0.89312261, 0.10687739],\n",
       "       [0.91175979, 0.08824021],\n",
       "       [0.03570627, 0.96429373],\n",
       "       [0.77423589, 0.22576411],\n",
       "       [0.82809097, 0.17190903],\n",
       "       [0.27335009, 0.72664991],\n",
       "       [0.41095636, 0.58904364],\n",
       "       [0.41677883, 0.58322117],\n",
       "       [0.30255724, 0.69744276],\n",
       "       [0.23219193, 0.76780807],\n",
       "       [0.42904108, 0.57095892],\n",
       "       [0.72270466, 0.27729534],\n",
       "       [0.6217827 , 0.3782173 ],\n",
       "       [0.20371163, 0.79628837],\n",
       "       [0.05210741, 0.94789259],\n",
       "       [0.77677403, 0.22322597],\n",
       "       [0.11773028, 0.88226972],\n",
       "       [0.83785616, 0.16214384],\n",
       "       [0.05970904, 0.94029096],\n",
       "       [0.03070294, 0.96929706],\n",
       "       [0.0218836 , 0.9781164 ],\n",
       "       [0.56750492, 0.43249508],\n",
       "       [0.35924456, 0.64075544],\n",
       "       [0.55122582, 0.44877418],\n",
       "       [0.15643693, 0.84356307],\n",
       "       [0.76262024, 0.23737976],\n",
       "       [0.63267612, 0.36732388],\n",
       "       [0.59654318, 0.40345682],\n",
       "       [0.00261832, 0.99738168],\n",
       "       [0.83421167, 0.16578833],\n",
       "       [0.59786443, 0.40213557],\n",
       "       [0.14037801, 0.85962199],\n",
       "       [0.84084988, 0.15915012],\n",
       "       [0.9678567 , 0.0321433 ],\n",
       "       [0.84650481, 0.15349519],\n",
       "       [0.03509667, 0.96490333],\n",
       "       [0.96245324, 0.03754676],\n",
       "       [0.74723939, 0.25276061],\n",
       "       [0.70026117, 0.29973883],\n",
       "       [0.47986928, 0.52013072],\n",
       "       [0.00367136, 0.99632864],\n",
       "       [0.78634741, 0.21365259],\n",
       "       [0.06364814, 0.93635186],\n",
       "       [0.58068352, 0.41931648],\n",
       "       [0.05007273, 0.94992727],\n",
       "       [0.90506055, 0.09493945],\n",
       "       [0.06616827, 0.93383173],\n",
       "       [0.66831758, 0.33168242],\n",
       "       [0.92734742, 0.07265258],\n",
       "       [0.55721961, 0.44278039],\n",
       "       [0.74709365, 0.25290635],\n",
       "       [0.77522455, 0.22477545],\n",
       "       [0.63486972, 0.36513028],\n",
       "       [0.01438777, 0.98561223],\n",
       "       [0.52834723, 0.47165277],\n",
       "       [0.02023639, 0.97976361],\n",
       "       [0.83864488, 0.16135512],\n",
       "       [0.01944111, 0.98055889],\n",
       "       [0.61155652, 0.38844348],\n",
       "       [0.92720153, 0.07279847],\n",
       "       [0.11587958, 0.88412042],\n",
       "       [0.00354271, 0.99645729],\n",
       "       [0.58325903, 0.41674097],\n",
       "       [0.28113047, 0.71886953],\n",
       "       [0.69464975, 0.30535025],\n",
       "       [0.06257916, 0.93742084],\n",
       "       [0.97562318, 0.02437682],\n",
       "       [0.11304658, 0.88695342],\n",
       "       [0.75903518, 0.24096482],\n",
       "       [0.0031531 , 0.9968469 ],\n",
       "       [0.55689244, 0.44310756],\n",
       "       [0.5739699 , 0.4260301 ],\n",
       "       [0.91482094, 0.08517906],\n",
       "       [0.51736949, 0.48263051],\n",
       "       [0.91039931, 0.08960069],\n",
       "       [0.52669851, 0.47330149],\n",
       "       [0.00317796, 0.99682204],\n",
       "       [0.04103979, 0.95896021],\n",
       "       [0.1322328 , 0.8677672 ],\n",
       "       [0.14655423, 0.85344577],\n",
       "       [0.33721267, 0.66278733],\n",
       "       [0.04056386, 0.95943614],\n",
       "       [0.09980328, 0.90019672],\n",
       "       [0.85588908, 0.14411092],\n",
       "       [0.11112541, 0.88887459],\n",
       "       [0.55233312, 0.44766688],\n",
       "       [0.88883871, 0.11116129],\n",
       "       [0.89061098, 0.10938902],\n",
       "       [0.1304353 , 0.8695647 ],\n",
       "       [0.90733258, 0.09266742],\n",
       "       [0.74998725, 0.25001275],\n",
       "       [0.75792848, 0.24207152],\n",
       "       [0.76793966, 0.23206034],\n",
       "       [0.47106832, 0.52893168],\n",
       "       [0.95073863, 0.04926137],\n",
       "       [0.983106  , 0.016894  ],\n",
       "       [0.92995953, 0.07004047],\n",
       "       [0.03517907, 0.96482093],\n",
       "       [0.49980354, 0.50019646],\n",
       "       [0.36629905, 0.63370095],\n",
       "       [0.848895  , 0.151105  ],\n",
       "       [0.8653365 , 0.1346635 ],\n",
       "       [0.52580322, 0.47419678],\n",
       "       [0.95457175, 0.04542825],\n",
       "       [0.41555788, 0.58444212],\n",
       "       [0.96203548, 0.03796452],\n",
       "       [0.99135738, 0.00864262],\n",
       "       [0.70670396, 0.29329604],\n",
       "       [0.06633492, 0.93366508],\n",
       "       [0.0508162 , 0.9491838 ],\n",
       "       [0.01960543, 0.98039457],\n",
       "       [0.84240385, 0.15759615],\n",
       "       [0.95530269, 0.04469731],\n",
       "       [0.788731  , 0.211269  ],\n",
       "       [0.97487695, 0.02512305],\n",
       "       [0.77665172, 0.22334828],\n",
       "       [0.93042505, 0.06957495],\n",
       "       [0.04241954, 0.95758046],\n",
       "       [0.23806093, 0.76193907],\n",
       "       [0.69716204, 0.30283796],\n",
       "       [0.0576568 , 0.9423432 ],\n",
       "       [0.0506892 , 0.9493108 ],\n",
       "       [0.89205545, 0.10794455],\n",
       "       [0.83103359, 0.16896641],\n",
       "       [0.38537408, 0.61462592],\n",
       "       [0.01845132, 0.98154868],\n",
       "       [0.82385323, 0.17614677],\n",
       "       [0.78506499, 0.21493501],\n",
       "       [0.03071641, 0.96928359],\n",
       "       [0.08149283, 0.91850717],\n",
       "       [0.77568633, 0.22431367],\n",
       "       [0.93130069, 0.06869931],\n",
       "       [0.01229257, 0.98770743],\n",
       "       [0.11056039, 0.88943961],\n",
       "       [0.80004548, 0.19995452],\n",
       "       [0.01102466, 0.98897534],\n",
       "       [0.04413068, 0.95586932],\n",
       "       [0.98195125, 0.01804875],\n",
       "       [0.03145616, 0.96854384],\n",
       "       [0.26099824, 0.73900176],\n",
       "       [0.8191255 , 0.1808745 ],\n",
       "       [0.39971207, 0.60028793],\n",
       "       [0.37467582, 0.62532418],\n",
       "       [0.7784229 , 0.2215771 ],\n",
       "       [0.74064048, 0.25935952],\n",
       "       [0.46013926, 0.53986074],\n",
       "       [0.53947825, 0.46052175],\n",
       "       [0.03656668, 0.96343332],\n",
       "       [0.00858922, 0.99141078],\n",
       "       [0.91595892, 0.08404108],\n",
       "       [0.11711168, 0.88288832],\n",
       "       [0.61465028, 0.38534972],\n",
       "       [0.0339813 , 0.9660187 ],\n",
       "       [0.01539839, 0.98460161],\n",
       "       [0.06560115, 0.93439885],\n",
       "       [0.90049527, 0.09950473],\n",
       "       [0.04924743, 0.95075257],\n",
       "       [0.87255588, 0.12744412],\n",
       "       [0.02147135, 0.97852865],\n",
       "       [0.64457615, 0.35542385],\n",
       "       [0.00987407, 0.99012593]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2304e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87641496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78 13]\n",
      " [29 80]]\n",
      "0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79        91\n",
      "           1       0.86      0.73      0.79       109\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.80      0.79       200\n",
      "weighted avg       0.80      0.79      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3403bb8",
   "metadata": {},
   "source": [
    "## Logistic Regression For Multiclass Classification\n",
    "\n",
    "Logistic regression is a popular algorithm used for binary classification problems. However, it can also be extended to handle multiclass classification problems through various techniques. In this response, I will explain two common approaches: one-vs-rest and softmax regression.\n",
    "\n",
    "**One-vs-Rest (OvR) Approach: The one-vs-rest approach, also known as one-vs-all, involves training a separate logistic regression model for each class, treating it as the positive class, and considering all other classes as the negative class. During prediction, the model that outputs the highest probability is chosen as the predicted class.**\n",
    "\n",
    "Here's a step-by-step breakdown of the one-vs-rest approach for multiclass logistic regression:\n",
    "\n",
    "1. Split your dataset into a training set and a test set.\n",
    "2. For each class in your target variable:\n",
    "   a. Create a binary variable where the positive class is the current class, and the negative class is all other classes.\n",
    "   b. Train a logistic regression model using the binary variable as the target variable and the original features as inputs.\n",
    "   c. Store the learned parameters (coefficients) for each model.\n",
    "\n",
    "During prediction:\n",
    "\n",
    "1. For a new input, pass it through all the trained models.\n",
    "2. Calculate the predicted probability for each class using the learned parameters.\n",
    "3. Assign the class with the highest probability as the predicted class.\n",
    "4. Softmax Regression (Multinomial Logistic Regression):- Softmax regression, also known as multinomial logistic regression, is another approach to handle multiclass classification with logistic regression. Unlike the one-vs-rest approach, softmax regression directly models the probabilities of each class using a single model.\n",
    "\n",
    "Here's how softmax regression works:\n",
    "\n",
    "1. Split your dataset into a training set and a test set.\n",
    "2. Encode your target variable using one-hot encoding, creating a binary matrix where each column represents a class.\n",
    "3. Train a logistic regression model with multiple outputs (equal to the number of classes).\n",
    "4. Use the softmax function to convert the outputs into probabilities, ensuring that the sum of probabilities for all classes adds up to 1.\n",
    "\n",
    "During prediction:\n",
    "\n",
    "1. For a new input, pass it through the trained model.\n",
    "2. Calculate the predicted probabilities for each class using the learned parameters and the softmax function.\n",
    "3. Assign the class with the highest probability as the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "39c9d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction with a multinomial logistic regression model\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2df28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the multinomial logistic regression model For multiclass classification\n",
    "model = LogisticRegression(multi_class='ovr', solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bb06954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "20fdcae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trianing model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a79e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "86010086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 2, 1, 2, 2, 2, 0, 0, 2, 0, 0, 1, 1, 0, 1, 2, 0, 0, 1, 0,\n",
       "       2, 1, 0, 1, 1, 0, 2, 2, 0, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 0, 2, 0, 1,\n",
       "       2, 1, 0, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 0, 1, 0, 1, 2, 0, 2, 2,\n",
       "       1, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 2, 1,\n",
       "       0, 1, 1, 2, 2, 2, 1, 2, 0, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       2, 2, 2, 2, 2, 2, 0, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2, 0, 0, 1, 1, 0,\n",
       "       2, 0, 1, 0, 2, 1, 2, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 1, 1, 2, 1, 0,\n",
       "       2, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc4c1c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.10622335e-02, 5.88916888e-01, 3.20020878e-01],\n",
       "       [7.74864218e-02, 8.83936419e-01, 3.85771592e-02],\n",
       "       [6.84414416e-01, 2.03496841e-01, 1.12088744e-01],\n",
       "       [1.43095699e-02, 9.01488946e-02, 8.95541536e-01],\n",
       "       [6.87497205e-02, 8.36642893e-01, 9.46073865e-02],\n",
       "       [1.09007702e-01, 3.07621844e-01, 5.83370453e-01],\n",
       "       [3.78594000e-01, 2.08265604e-01, 4.13140396e-01],\n",
       "       [3.14084906e-01, 1.75940674e-01, 5.09974420e-01],\n",
       "       [5.14671931e-01, 1.90311178e-01, 2.95016891e-01],\n",
       "       [5.97817613e-01, 3.02410459e-01, 9.97719283e-02],\n",
       "       [4.20115939e-02, 3.31570100e-01, 6.26418306e-01],\n",
       "       [4.86740270e-01, 1.04804858e-01, 4.08454873e-01],\n",
       "       [8.01115911e-01, 3.37497449e-02, 1.65134344e-01],\n",
       "       [8.98140961e-02, 6.97976196e-01, 2.12209707e-01],\n",
       "       [7.29023255e-02, 8.39105805e-01, 8.79918698e-02],\n",
       "       [5.10619176e-01, 2.09225440e-01, 2.80155384e-01],\n",
       "       [1.24309039e-01, 7.90819633e-01, 8.48713286e-02],\n",
       "       [3.42847759e-03, 3.71703093e-01, 6.24868429e-01],\n",
       "       [6.26581443e-01, 4.39043343e-02, 3.29514222e-01],\n",
       "       [6.49563084e-01, 8.84542905e-02, 2.61982626e-01],\n",
       "       [1.16767688e-02, 7.95935769e-01, 1.92387462e-01],\n",
       "       [4.53777395e-01, 2.50611909e-01, 2.95610696e-01],\n",
       "       [2.40753935e-01, 2.05761283e-01, 5.53484783e-01],\n",
       "       [6.39589313e-03, 7.31480382e-01, 2.62123725e-01],\n",
       "       [6.76678217e-01, 2.84368516e-01, 3.89532674e-02],\n",
       "       [3.71144629e-01, 6.05465992e-01, 2.33893796e-02],\n",
       "       [3.18813142e-01, 4.52639647e-01, 2.28547211e-01],\n",
       "       [6.83244693e-01, 2.38493541e-01, 7.82617662e-02],\n",
       "       [2.74203907e-02, 1.43220881e-01, 8.29358728e-01],\n",
       "       [3.13453132e-02, 2.67360990e-01, 7.01293697e-01],\n",
       "       [6.36362405e-01, 4.70448486e-03, 3.58933110e-01],\n",
       "       [1.11799721e-01, 8.56581124e-01, 3.16191547e-02],\n",
       "       [5.54943145e-01, 8.55020092e-02, 3.59554846e-01],\n",
       "       [4.30083852e-01, 4.61209131e-01, 1.08707017e-01],\n",
       "       [6.10376172e-01, 2.19537737e-02, 3.67670055e-01],\n",
       "       [3.65214793e-01, 2.54965161e-01, 3.79820046e-01],\n",
       "       [5.17863315e-01, 1.22604790e-01, 3.59531896e-01],\n",
       "       [3.71352074e-01, 1.87646632e-01, 4.41001294e-01],\n",
       "       [1.85282225e-01, 7.85600153e-01, 2.91176218e-02],\n",
       "       [6.31443197e-01, 9.51978334e-02, 2.73358970e-01],\n",
       "       [5.28098566e-01, 1.94450574e-01, 2.77450860e-01],\n",
       "       [6.63574790e-01, 3.11069991e-01, 2.53552196e-02],\n",
       "       [1.40129433e-01, 7.20524399e-01, 1.39346168e-01],\n",
       "       [3.69186516e-01, 3.55908963e-01, 2.74904522e-01],\n",
       "       [1.49831309e-01, 8.30003915e-01, 2.01647764e-02],\n",
       "       [1.41605348e-01, 7.84016984e-01, 7.43776686e-02],\n",
       "       [5.90750656e-01, 6.80892471e-02, 3.41160097e-01],\n",
       "       [5.83675457e-01, 3.42831031e-02, 3.82041440e-01],\n",
       "       [4.39607846e-01, 3.16608749e-01, 2.43783405e-01],\n",
       "       [1.20975894e-01, 2.00264222e-01, 6.78759884e-01],\n",
       "       [5.26405923e-02, 8.90741131e-01, 5.66182768e-02],\n",
       "       [3.58708079e-01, 2.12027887e-01, 4.29264034e-01],\n",
       "       [4.96415374e-01, 3.10647413e-01, 1.92937213e-01],\n",
       "       [1.35499109e-02, 4.50637904e-01, 5.35812185e-01],\n",
       "       [8.09176456e-02, 2.47967422e-01, 6.71114933e-01],\n",
       "       [6.22235387e-02, 2.05684246e-01, 7.32092216e-01],\n",
       "       [5.14164878e-01, 1.33257283e-01, 3.52577839e-01],\n",
       "       [3.05518218e-01, 6.26025271e-01, 6.84565112e-02],\n",
       "       [3.65365207e-01, 5.22684584e-01, 1.11950209e-01],\n",
       "       [5.71077017e-01, 6.20385399e-02, 3.66884443e-01],\n",
       "       [5.36082234e-01, 6.55359378e-02, 3.98381829e-01],\n",
       "       [9.59824669e-02, 4.03215726e-01, 5.00801807e-01],\n",
       "       [8.87691162e-01, 3.15977004e-02, 8.07111381e-02],\n",
       "       [2.03425706e-01, 1.14972672e-01, 6.81601623e-01],\n",
       "       [5.57528996e-01, 1.33785541e-02, 4.29092450e-01],\n",
       "       [4.58837340e-01, 4.82103754e-01, 5.90589062e-02],\n",
       "       [4.81245190e-02, 3.21607763e-02, 9.19714705e-01],\n",
       "       [3.25727105e-01, 4.77990633e-01, 1.96282263e-01],\n",
       "       [5.40258785e-01, 1.16425375e-01, 3.43315840e-01],\n",
       "       [5.36381766e-01, 3.85670551e-01, 7.79476834e-02],\n",
       "       [2.21630739e-02, 3.46671630e-01, 6.31165296e-01],\n",
       "       [4.28634574e-01, 1.21524859e-02, 5.59212940e-01],\n",
       "       [4.71906371e-01, 8.47974161e-03, 5.19613887e-01],\n",
       "       [1.17969729e-01, 8.13613864e-01, 6.84164071e-02],\n",
       "       [3.96322487e-01, 5.02477466e-01, 1.01200046e-01],\n",
       "       [8.68042080e-02, 2.72586792e-01, 6.40609000e-01],\n",
       "       [5.81712785e-02, 2.47426784e-01, 6.94401937e-01],\n",
       "       [1.97969897e-01, 1.42289264e-01, 6.59740839e-01],\n",
       "       [8.02402992e-02, 3.82841555e-01, 5.36918146e-01],\n",
       "       [3.11412798e-01, 1.26400165e-01, 5.62187037e-01],\n",
       "       [8.48688254e-01, 8.97967946e-03, 1.42332067e-01],\n",
       "       [4.57160024e-02, 6.01115670e-01, 3.53168328e-01],\n",
       "       [8.08903177e-01, 6.94162866e-02, 1.21680537e-01],\n",
       "       [2.11293559e-01, 6.26724991e-01, 1.61981450e-01],\n",
       "       [7.14773989e-02, 7.11749389e-02, 8.57347662e-01],\n",
       "       [5.40245841e-01, 1.08354558e-01, 3.51399601e-01],\n",
       "       [6.12569195e-02, 2.40240005e-01, 6.98503075e-01],\n",
       "       [3.31346022e-02, 3.56755982e-01, 6.10109416e-01],\n",
       "       [3.16493415e-01, 4.74029013e-01, 2.09477571e-01],\n",
       "       [2.53102449e-01, 6.29991966e-01, 1.16905585e-01],\n",
       "       [3.70178879e-01, 1.75948074e-01, 4.53873047e-01],\n",
       "       [6.86798110e-01, 2.99391087e-01, 1.38108032e-02],\n",
       "       [6.57624184e-01, 2.63659576e-01, 7.87162400e-02],\n",
       "       [6.12796630e-01, 1.67584056e-01, 2.19619314e-01],\n",
       "       [1.40038755e-01, 7.28881089e-01, 1.31080156e-01],\n",
       "       [7.67453256e-01, 6.26081708e-02, 1.69938573e-01],\n",
       "       [6.40579484e-01, 3.37022011e-01, 2.23985058e-02],\n",
       "       [5.54824666e-01, 1.92111395e-02, 4.25964195e-01],\n",
       "       [1.50721031e-02, 8.33235902e-01, 1.51691994e-01],\n",
       "       [4.92408601e-01, 2.50225319e-01, 2.57366081e-01],\n",
       "       [6.57075250e-01, 4.74873231e-03, 3.38176018e-01],\n",
       "       [2.39504243e-01, 6.57814209e-01, 1.02681548e-01],\n",
       "       [5.66811247e-01, 7.64489914e-03, 4.25543854e-01],\n",
       "       [1.97561926e-01, 5.76599324e-01, 2.25838751e-01],\n",
       "       [5.48631675e-01, 7.53205178e-02, 3.76047808e-01],\n",
       "       [5.99998071e-01, 9.33386396e-02, 3.06663290e-01],\n",
       "       [1.70405250e-01, 7.05329649e-01, 1.24265101e-01],\n",
       "       [5.89895524e-01, 4.56374424e-02, 3.64467034e-01],\n",
       "       [3.00681882e-02, 8.97197778e-02, 8.80212034e-01],\n",
       "       [3.09707320e-01, 5.65473703e-01, 1.24818977e-01],\n",
       "       [7.87337029e-01, 8.45494273e-02, 1.28113543e-01],\n",
       "       [1.22482545e-01, 6.02424006e-01, 2.75093448e-01],\n",
       "       [2.87116580e-02, 8.92057234e-01, 7.92311079e-02],\n",
       "       [2.97772067e-01, 7.82382335e-02, 6.23989699e-01],\n",
       "       [2.01046538e-01, 1.40210175e-01, 6.58743288e-01],\n",
       "       [3.27182212e-01, 3.03165645e-01, 3.69652143e-01],\n",
       "       [1.85270884e-01, 7.50463697e-01, 6.42654184e-02],\n",
       "       [2.67629110e-01, 1.78857189e-01, 5.53513700e-01],\n",
       "       [7.60742658e-01, 1.28016718e-01, 1.11240624e-01],\n",
       "       [4.71126800e-01, 2.67506843e-01, 2.61366357e-01],\n",
       "       [4.34795523e-02, 2.68703514e-01, 6.87816934e-01],\n",
       "       [3.53855776e-01, 4.93263467e-01, 1.52880757e-01],\n",
       "       [5.79981100e-01, 1.14408922e-01, 3.05609978e-01],\n",
       "       [4.35746553e-02, 5.37535267e-01, 4.18890078e-01],\n",
       "       [3.82484181e-01, 6.12545067e-01, 4.97075159e-03],\n",
       "       [3.31702917e-01, 4.71800755e-01, 1.96496328e-01],\n",
       "       [4.92495553e-01, 1.53942860e-01, 3.53561587e-01],\n",
       "       [7.10129801e-01, 2.63336570e-01, 2.65336283e-02],\n",
       "       [5.18450823e-01, 2.16780058e-01, 2.64769119e-01],\n",
       "       [5.86238594e-01, 5.97569777e-02, 3.54004429e-01],\n",
       "       [5.61017786e-01, 4.20242853e-01, 1.87393608e-02],\n",
       "       [6.87496673e-01, 6.31466171e-02, 2.49356710e-01],\n",
       "       [5.78459116e-02, 2.98213162e-01, 6.43940926e-01],\n",
       "       [1.54929449e-01, 4.34947617e-02, 8.01575790e-01],\n",
       "       [6.30620677e-02, 4.36592344e-01, 5.00345588e-01],\n",
       "       [1.50058412e-01, 1.34663859e-01, 7.15277729e-01],\n",
       "       [3.04644535e-01, 1.20655511e-01, 5.74699954e-01],\n",
       "       [2.11087278e-01, 1.11774333e-01, 6.77138389e-01],\n",
       "       [6.91814625e-01, 5.94877015e-02, 2.48697674e-01],\n",
       "       [3.95764106e-02, 4.72653519e-01, 4.87770071e-01],\n",
       "       [4.64464611e-01, 4.85425030e-01, 5.01103591e-02],\n",
       "       [3.07752753e-01, 6.83607436e-01, 8.63981140e-03],\n",
       "       [4.28094031e-01, 3.86747980e-01, 1.85157989e-01],\n",
       "       [2.10664779e-01, 7.52123991e-01, 3.72112296e-02],\n",
       "       [2.23969850e-01, 9.70829765e-02, 6.78947173e-01],\n",
       "       [5.73366035e-01, 1.10925187e-01, 3.15708778e-01],\n",
       "       [2.67075629e-01, 4.47897405e-01, 2.85026966e-01],\n",
       "       [5.23029302e-01, 1.13181531e-01, 3.63789167e-01],\n",
       "       [2.95410899e-01, 6.01583999e-02, 6.44430701e-01],\n",
       "       [6.00835494e-01, 9.11244082e-02, 3.08040097e-01],\n",
       "       [5.55153768e-01, 5.44772543e-02, 3.90368977e-01],\n",
       "       [3.23644464e-01, 5.57555186e-01, 1.18800350e-01],\n",
       "       [1.08190704e-01, 5.09250894e-01, 3.82558402e-01],\n",
       "       [4.63471821e-01, 1.82663074e-01, 3.53865105e-01],\n",
       "       [1.48740695e-01, 8.19371621e-02, 7.69322143e-01],\n",
       "       [4.99810443e-01, 4.32988212e-01, 6.72013450e-02],\n",
       "       [3.51254436e-01, 4.09190136e-01, 2.39555428e-01],\n",
       "       [5.55994941e-01, 2.10565993e-01, 2.33439065e-01],\n",
       "       [2.63987489e-01, 1.33509082e-02, 7.22661602e-01],\n",
       "       [8.67742662e-02, 8.08162757e-01, 1.05062977e-01],\n",
       "       [2.47774218e-01, 2.57074443e-01, 4.95151339e-01],\n",
       "       [5.44508158e-01, 1.21331705e-01, 3.34160138e-01],\n",
       "       [1.95777117e-02, 7.52180950e-01, 2.28241338e-01],\n",
       "       [4.29429954e-01, 4.33401795e-01, 1.37168251e-01],\n",
       "       [5.81117251e-01, 8.04401403e-02, 3.38442609e-01],\n",
       "       [2.41535498e-01, 7.41302378e-01, 1.71621239e-02],\n",
       "       [2.74865287e-01, 7.47605615e-02, 6.50374152e-01],\n",
       "       [2.58073060e-01, 6.06895646e-01, 1.35031294e-01],\n",
       "       [5.65177540e-01, 2.41455161e-01, 1.93367300e-01],\n",
       "       [1.62649464e-01, 9.50362008e-02, 7.42314335e-01],\n",
       "       [4.95815034e-01, 1.09856688e-01, 3.94328277e-01],\n",
       "       [3.85408650e-02, 8.89315730e-01, 7.21434046e-02],\n",
       "       [6.80696097e-02, 8.90239603e-01, 4.16907871e-02],\n",
       "       [4.08639241e-01, 1.79413834e-01, 4.11946925e-01],\n",
       "       [2.31796340e-01, 5.15446138e-01, 2.52757521e-01],\n",
       "       [5.95232079e-01, 3.68041275e-01, 3.67266454e-02],\n",
       "       [2.44253344e-02, 2.12304426e-01, 7.63270240e-01],\n",
       "       [3.41142825e-01, 6.41717307e-01, 1.71398673e-02],\n",
       "       [2.09164984e-01, 7.79452291e-01, 1.13827250e-02],\n",
       "       [4.14537723e-01, 2.90408104e-01, 2.95054173e-01],\n",
       "       [2.59669737e-04, 5.63075449e-01, 4.36664882e-01],\n",
       "       [4.97852282e-01, 2.55045468e-01, 2.47102251e-01],\n",
       "       [2.65814831e-03, 6.37765236e-01, 3.59576616e-01],\n",
       "       [4.97576682e-01, 4.55793929e-01, 4.66293889e-02],\n",
       "       [1.27632344e-02, 4.62427447e-01, 5.24809318e-01],\n",
       "       [5.76446060e-01, 1.41054478e-02, 4.09448492e-01],\n",
       "       [5.91684162e-01, 3.62078832e-01, 4.62370060e-02],\n",
       "       [5.34032738e-01, 3.09569362e-02, 4.35010326e-01],\n",
       "       [6.02739479e-01, 3.19529673e-01, 7.77308481e-02],\n",
       "       [4.48960195e-01, 1.58681496e-01, 3.92358308e-01],\n",
       "       [1.56731252e-02, 8.96228515e-01, 8.80983595e-02],\n",
       "       [7.15731915e-01, 5.75461947e-02, 2.26721890e-01],\n",
       "       [5.55463666e-01, 2.80560905e-02, 4.16480244e-01],\n",
       "       [2.62769416e-02, 9.02329421e-01, 7.13936373e-02],\n",
       "       [4.36386267e-01, 5.19008196e-01, 4.46055366e-02],\n",
       "       [7.18567005e-01, 5.74886506e-02, 2.23944345e-01],\n",
       "       [7.64487631e-01, 7.90372250e-02, 1.56475144e-01],\n",
       "       [4.40105268e-01, 1.28831604e-01, 4.31063127e-01],\n",
       "       [1.76705592e-01, 6.03845030e-01, 2.19449378e-01],\n",
       "       [6.70538963e-01, 1.07176120e-02, 3.18743425e-01]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1efbe180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "02eeb4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38 34 35]\n",
      " [37 30 26]\n",
      " [ 0  0  0]]\n",
      "0.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.36      0.42       107\n",
      "           1       0.47      0.32      0.38        93\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.34       200\n",
      "   macro avg       0.33      0.23      0.27       200\n",
      "weighted avg       0.49      0.34      0.40       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0dbdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41391e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dceec94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631fb26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0d554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
