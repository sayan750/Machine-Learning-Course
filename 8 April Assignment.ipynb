{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c7664a",
   "metadata": {},
   "source": [
    "### 1.\n",
    "\n",
    "When developing an SVM regression model to predict house prices based on various characteristics, several regression metrics can be utilized to assess the model's performance. The choice of the metric depends on the specific requirements and preferences of the task. Here are a few commonly used regression metrics that you can consider:\n",
    "\n",
    "1. Mean Squared Error (MSE): MSE calculates the average squared difference between the predicted and actual house prices. It is widely used and provides a good overall measure of the model's performance. However, it emphasizes larger errors due to the squared term.\n",
    "\n",
    "2. Root Mean Squared Error (RMSE): RMSE is the square root of the MSE and is beneficial because it is on the same scale as the target variable. It provides a more interpretable measure of the average prediction error.\n",
    "\n",
    "3. Mean Absolute Error (MAE): MAE calculates the average absolute difference between the predicted and actual house prices. It is less sensitive to outliers compared to MSE but does not penalize larger errors as much. MAE is often preferred when outliers are present in the dataset.\n",
    "\n",
    "4. R-squared (R²) Score: R² measures the proportion of variance in the target variable (house prices) explained by the model. It ranges from 0 to 1, with higher values indicating a better fit. R² can be useful for evaluating the overall goodness of fit of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f9598",
   "metadata": {},
   "source": [
    "### 2.\n",
    "\n",
    "If my goal is to predict the actual price of a house as accurately as possible, the most appropriate evaluation metric would be the mean squared error (MSE) rather than the coefficient of determination (R-squared).\n",
    "\n",
    "MSE measures the average squared difference between the predicted and actual values. In the context of house price prediction, MSE quantifies the average squared difference between the predicted prices and the true prices. Lower MSE values indicate better accuracy in predicting house prices. By minimizing the MSE, you are striving to reduce the overall prediction errors and improve the accuracy of your regression model.\n",
    "\n",
    "R-squared, on the other hand, measures the proportion of the variance in the dependent variable (house prices) that can be explained by the independent variables (features) in your model. While R-squared is a useful metric for understanding the proportion of variance explained by the model, it does not directly reflect the accuracy of predicting individual house prices. R-squared can be misleading, especially when dealing with nonlinear relationships or outliers.\n",
    "\n",
    "Therefore, to assess the accuracy of predicting individual house prices, MSE is a more appropriate metric than R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e4acff",
   "metadata": {},
   "source": [
    "### 3.\n",
    "\n",
    "When dealing with a dataset that contains a significant number of outliers, it is important to choose a regression metric that is robust to outliers. One such metric is the Mean Absolute Error (MAE). The MAE is defined as the average of the absolute differences between the predicted and actual values. Unlike other regression metrics such as the Mean Squared Error (MSE), which squares the differences, the MAE gives equal weight to all the errors. This makes it less sensitive to outliers because it does not amplify the effect of large errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ecd687",
   "metadata": {},
   "source": [
    "### 4.\n",
    "\n",
    "When evaluating the performance of an SVM regression model using a polynomial kernel, and considering that both the Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) values are very close, it is generally recommended to use the RMSE as the preferred metric. The RMSE is a more interpretable metric because it is in the same unit as the target variable, unlike the MSE, which is in squared units. By taking the square root of the MSE to calculate the RMSE, we can obtain an error metric that is directly comparable to the original scale of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbfde00",
   "metadata": {},
   "source": [
    "### 5.\n",
    "\n",
    "If my goal is to measure how well the model explains the variance in the target variable, the most appropriate evaluation metric would be the coefficient of determination, also known as R-squared (R²). R-squared provides a measure of the proportion of the variance in the target variable that is explained by the model. R-squared ranges from 0 to 1, with 0 indicating that the model does not explain any of the variance in the target variable and 1 indicating that the model explains all of the variance. A higher R-squared value indicates a better fit of the model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a59be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
